{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Top 10 Important Features:\n",
      "                        Feature  Importance\n",
      "20       Wants_Higher_Education    0.214881\n",
      "0                        School    0.104122\n",
      "3                       Address    0.053598\n",
      "14           Number_of_Failures    0.051273\n",
      "29           Number_of_Absences    0.050689\n",
      "2                           Age    0.048365\n",
      "10   Reason_for_Choosing_School    0.048029\n",
      "26  Weekend_Alcohol_Consumption    0.046675\n",
      "19             Attended_Nursery    0.045654\n",
      "11                     Guardian    0.043416\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.90      0.83      0.86       169\n",
      "        True       0.26      0.38      0.31        26\n",
      "\n",
      "    accuracy                           0.77       195\n",
      "   macro avg       0.58      0.61      0.58       195\n",
      "weighted avg       0.81      0.77      0.79       195\n",
      "\n",
      "\n",
      "Balanced Accuracy: 0.606508875739645\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"student_dropout.csv\")\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in df.select_dtypes(include=[\"object\"]).columns:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Exclude 'Dropped_Out', 'Final_Grade', 'Grade_1', and 'Grade_2' from features (X)\n",
    "X = df.drop([\"Dropped_Out\", \"Final_Grade\", \"Grade_1\", \"Grade_2\"], axis=1)  # Drop the specified columns from the feature set\n",
    "y = df[\"Dropped_Out\"]  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Apply SMOTE to balance the classes in the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Hyperparameter tuning with GridSearchCV\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42, class_weight='balanced'), param_grid, cv=5)\n",
    "grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Best parameters from GridSearchCV\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Train the model with the best parameters\n",
    "dtree = grid_search.best_estimator_\n",
    "dtree.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Get feature importances from the decision tree model\n",
    "feature_importances = dtree.feature_importances_\n",
    "\n",
    "# Create a DataFrame with features and their importance scores\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by the importance score in descending order\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top important features\n",
    "print(\"Top 10 Important Features:\")\n",
    "print(importance_df.head(10))\n",
    "\n",
    "# Evaluate the model using the test set\n",
    "y_pred = dtree.predict(X_test)\n",
    "\n",
    "# Print classification report for detailed evaluation\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Calculate and print balanced accuracy score\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nBalanced Accuracy: {balanced_accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
